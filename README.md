# Проект контур

## Описание

В рамках сего макета будем реализовывать следующие штуки:
- Инфра
    1. Запуск всего хозяйства в кубере
- Программа минимум:
    1. Интеграция с каналами коммуникации (телеграмма, email)
    2. Поддержка жизненого цикла в workflow
- Программа максимум: 
    1. Конфигурирование workflow (по yaml файлу)
    2. Конфигурирование инфомодели 
    3. Конфигурирование адаптера
- Программа максимум*:
    1. Для всего запускаем фронт

## Основные компоненты системы

- service-communication (сервис коммуникации) предназначен для инкапусялиции логики работы с каналами, взаимодействует с ядром как синхронно, так и асинхронно. Сервис коммуникаций оперирует сущностью сообщение (оно может быть как в email или в мессенджере). Сервис коммуникаций может:
- принимать сообщения, выгребать новые сообщения по апи и преобразовывать их к внутреннему формату
- выполнять синхронные операции к воркфлоу (аналоги действий в мессенджере)
- отправлять сообщение в нужный канал коммуникации.
*Тут вопрос хотим ли логику отложенной отправки сообщений сделать в этом сервисе*

- service-gateway (сервис шлюз). По большей части взаимодействие синхронное, пока не придумал что можем асинхронно делать, мб получать сигналы от автоматизаторов и дальше проталкивать обращение по жизненному циклу.

- service-workflow (сердце тикетной системы)

## План-банан

1. сделать сервис communication, затащить пару детекторов
    - :done 01.05.2025
2. сделать сервис gateway (сделать rpc сервер)
    - :done 01.05.2025
3. запустить и наладить взаимодействие прочитали сообщение дернули гетвей
    - :done 01.05.2025
4. запуск temporal
    - к сожалению запустить в кубере не получилось, смог запустить только локально, и прокидываю `host.docker.internal:7233` для подключения темпоралу
5. запуск сердца в кубере и подключение к темпоралу 
    - :done 04.05.2025
6. запуск kafka в кубере и подключение сервисов к нему
    - :done 05.05.2025
7. описание жизненого цикла для сердца
    - :done 09.05.2025
8. реализация жизненного цикла
    - 1. делаем интеграцию service-workflow и kafka
    - 2. делаем сервис service-tickets для хранения тикетов
    - 3. реализовываем цепочку:
        - написали на почту, в телегу
        - отправили событие в кафка из communications
        - получили событие и запустили воркфлоу:
            - 1. процесс обработки сообщений:
                - если открытых титкетов от этого пользователя нет, создаем тикет
                - если тикеты есть, просто пишем в таблицу сообщение пользователя
            - 2. запустиили процесс классификации и сохранили в сервисе tickets инфу о классифкации
            - 3. ждем назначения, поддержать обработку сигнала назначения, при назначении пишем в бд и толкаем дальше
            - 4. ждем решение и запускаем таймер, сигнал решения - переводит в решенное обращение
9. создание фронта и сервиса gateway для получения данных 


## Как это запустить?

1. запуск миникуба -  `minikube start`
2. запуск темпорала - `temporal server start-dev --ui-port 8080 --ip 0.0.0.0`. После запуска он у нас будет висеть на порте `localhost:7233` 
3. запуск компонентов:
    - 3.1. почтовый сервер `kubectl apply -f k8s/mailhog.yaml`
    - 3.2. поднимаем базку и миграции: 
        - `kubectl apply -f k8s/postgres.yaml`
        - ждем когда постгри запустится
        - хреновасто, но пофиг - `kubectl apply -f k8s/job-migrate.yaml`
        - секреты 
            - для постгри: `kubectl create secret generic postgres-secret --from-literal=username=postgres --from-literal=password=postgres --dry-run=client -o yaml | kubectl apply -f -`
            - как получить секрет: `kubectl get secret postgres-secret -o yaml | grep -v "^\s*namespace:"`
    - 3.3. гетвей - `kubectl apply -f k8s/service-gateway.yaml`
    - 3.4. гетвей - `kubectl apply -f k8s/service-communications.yaml`
    - 3.5. воркфлоу -  `kubectl apply -f k8s/service-workflow`
        - тут у нас у под капотом и api и worker которые обращаются к локальному темпоралу
    - 3.6. кафка - `kubectl apply -f k8s/kafka.yaml`. Тут важно учесть, что такой конфиг валидно работает для кубер окружения. В случае если хочется работать с кафкой локально нужно поправить конфиг так (возможно есть более разумное решение, но быстрого варианта не придумал):
    ```yaml
        - name: KAFKA_CFG_ADVERTISED_LISTENERS
        value: "PLAINTEXT://kafka:9092"     #так будет работать для кубера
        value: "PLAINTEXT://localhost:9092" #так будет работать для локали
    ```
    - 3.7. ка
